{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dialogue box for folder selection. Please choose a folder.\n",
      "Folder selected:\n",
      "C:/Users/lwolf/Desktop/MY PROJECTS/exerPythCombineFiles/FileTypes/FileTypes\n"
     ]
    }
   ],
   "source": [
    "# Have user select excel sheet with needed data.\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.lift()\n",
    "root.withdraw()\n",
    "\n",
    "# This code block will open a specific file. (Uncomment the lines after this comment to use them.)\n",
    "#print('Opening dialogue box for file selection. Please choose a file.')\n",
    "#file_path = filedialog.askopenfilename()\n",
    "#print('File selected:')\n",
    "\n",
    "# This code block will get a directory path. (Uncomment the lines after this comment to use them.)\n",
    "print('Opening dialogue box for folder selection. Please choose a folder.')\n",
    "file_path = filedialog.askdirectory()\n",
    "print('Folder selected:')\n",
    "\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Aunt.csv', 'boys.xlsx', 'Combine multiple file types with same columns into dataframe.ipynb', 'Combine multiple file types with same columns into dataframe.py', 'CSVtest.csv', 'CSVtest2.csv', 'CSVtest3.csv', 'EXCELtest.xlsx', 'EXCELtest2.xlsx', 'EXCELtest3.xlsx', 'girls.xlsx', 'Joan.json', 'JSONtest.json', 'JSONtest2.json', 'JSONtest3.json', 'JSONtest4.json', 'Matthew.xml', 'NewCombinedFile_2020-10-13.csv', 'peter.json', 'stephanie.xml', 'uncles.csv', 'XMLtest.xml', 'XMLtest2.xml', 'XMLtest3.xml', 'XMLtest4.xml']\n",
      "CSVfiles:  ['Aunt.csv', 'CSVtest.csv', 'CSVtest2.csv', 'CSVtest3.csv', 'NewCombinedFile_2020-10-13.csv', 'uncles.csv'] \n",
      "Excel files:  ['boys.xlsx', 'EXCELtest.xlsx', 'EXCELtest2.xlsx', 'EXCELtest3.xlsx', 'girls.xlsx'] \n",
      "JSON files:  ['Joan.json', 'JSONtest.json', 'JSONtest2.json', 'JSONtest3.json', 'JSONtest4.json', 'peter.json'] \n",
      "XML files:  ['Matthew.xml', 'stephanie.xml', 'XMLtest.xml', 'XMLtest2.xml', 'XMLtest3.xml', 'XMLtest4.xml']\n"
     ]
    }
   ],
   "source": [
    "# Make sure correct files are recognized.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List the files in the directory.\n",
    "files = os.listdir(file_path)\n",
    "print(files)\n",
    "\n",
    "# List of file types we want to add\n",
    "file_types = ['xlsx','csv','json','xml']\n",
    "\n",
    "# create a list of files for each file type\n",
    "files_csv = [f for f in files if f[-3:] == 'csv']\n",
    "files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
    "files_json = [f for f in files if f[-4:] == 'json']\n",
    "files_xml = [f for f in files if f[-3:] == 'xml']\n",
    "\n",
    "print('CSVfiles: ', files_csv, '\\nExcel files: ', files_xlsx, '\\nJSON files: ', files_json, '\\nXML files: ', files_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holli Gayle</td>\n",
       "      <td>11/12/1974</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>Aunt.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nina Shae</td>\n",
       "      <td>9/24/1973</td>\n",
       "      <td>150</td>\n",
       "      <td>35</td>\n",
       "      <td>Aunt.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack Smith</td>\n",
       "      <td>4/1/2019</td>\n",
       "      <td>185</td>\n",
       "      <td>91</td>\n",
       "      <td>CSVtest.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack Black</td>\n",
       "      <td>4/2/2019</td>\n",
       "      <td>183</td>\n",
       "      <td>91</td>\n",
       "      <td>CSVtest.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brock Bricks</td>\n",
       "      <td>4/10/2019</td>\n",
       "      <td>185</td>\n",
       "      <td>95</td>\n",
       "      <td>CSVtest2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>stephanie sue</td>\n",
       "      <td>05/08/1989</td>\n",
       "      <td>120</td>\n",
       "      <td>50</td>\n",
       "      <td>stephanie.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>02/08/2019</td>\n",
       "      <td>180</td>\n",
       "      <td>100</td>\n",
       "      <td>XMLtest.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>John Smithe</td>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>185</td>\n",
       "      <td>101</td>\n",
       "      <td>XMLtest2.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Brett Smithe</td>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>179</td>\n",
       "      <td>99</td>\n",
       "      <td>XMLtest3.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Matthew Garrett</td>\n",
       "      <td>07/10/1985</td>\n",
       "      <td>195</td>\n",
       "      <td>None</td>\n",
       "      <td>XMLtest4.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name        date height weight         Source\n",
       "0       Holli Gayle  11/12/1974    170     50       Aunt.csv\n",
       "1         Nina Shae   9/24/1973    150     35       Aunt.csv\n",
       "2        Jack Smith    4/1/2019    185     91    CSVtest.csv\n",
       "3        Jack Black    4/2/2019    183     91    CSVtest.csv\n",
       "4      Brock Bricks   4/10/2019    185     95   CSVtest2.csv\n",
       "..              ...         ...    ...    ...            ...\n",
       "59    stephanie sue  05/08/1989    120     50  stephanie.xml\n",
       "60       John Smith  02/08/2019    180    100    XMLtest.xml\n",
       "61      John Smithe  03/08/2019    185    101   XMLtest2.xml\n",
       "62     Brett Smithe  05/08/2019    179     99   XMLtest3.xml\n",
       "63  Matthew Garrett  07/10/1985    195   None   XMLtest4.xml\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Iterate through the files in the directory and append each one into the dataframe.\n",
    "# This will only work correctly if the files have the exact same column names.\n",
    "df_list = []\n",
    "for f in files_csv:\n",
    "    data = pd.read_csv(str(file_path) + '/' + str(f), index_col=None, header=0)\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "for f in files_xlsx:\n",
    "    data = pd.read_excel(str(file_path) + '/' + str(f))\n",
    "    data['Source'] = f\n",
    "    df_list.append(data)\n",
    "    \n",
    "# Iterate through the json files and add data from each to a list.\n",
    "json_list = []\n",
    "for f in files_json:\n",
    "    with open(str(file_path) + '/' + str(f)) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        json_obj['Source'] = f\n",
    "        json_list.append(json_obj.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(json_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "    \n",
    "# Iterate through the xml files and add data from each to a list.\n",
    "xml_list = []\n",
    "for f in files_xml:\n",
    "    # create element tree object \n",
    "    tree = ET.parse(str(file_path) + '/' + str(f))\n",
    "    # get root element \n",
    "    root = tree.getroot()\n",
    "    # create dictionary from XML tags and values\n",
    "    itemdict = {}\n",
    "    for item in root:\n",
    "        itemdict[item.tag] = item.text\n",
    "    itemdict['Source'] = f\n",
    "    xml_list.append(itemdict.copy())\n",
    "# Turn the combined list into a dataframe.\n",
    "data = pd.DataFrame(xml_list)\n",
    "# Add the data frame to the list of dataframes.\n",
    "df_list.append(data)\n",
    "\n",
    "# Combine all the data frames in the list into a single data frame.    \n",
    "df =  pd.concat(df_list, axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# See how many rows the data frame has.\n",
    "print(len(df.index))\n",
    "\n",
    "# Show the data in the data frame.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-13\n",
      "C:/Users/lwolf/Desktop/MY PROJECTS/exerPythCombineFiles/FileTypes/FileTypes/NewCombinedFile_2020-10-13.csv\n",
      "File saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the dataframe to a new combined csv file.\n",
    "\n",
    "# Add today's date to the name of the new file.\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(today)\n",
    "\n",
    "filename = str(file_path) + '/' + 'NewCombinedFile_' + str(today) + '.csv'\n",
    "print(filename)\n",
    "\n",
    "df.to_csv(filename, index=False)\n",
    "print('File saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
